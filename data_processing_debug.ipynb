{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Назначение:</b> <br>\n",
    "Подготовка кастомного Dataset-класса и тестирование Dataloader-класса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from transformers import AutoImageProcessor\n",
    "import torch\n",
    "\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCarDataset(Dataset):\n",
    "    def __init__(self, part_name, fronts_info_path, processor):\n",
    "        data_info = pd.read_csv(fronts_info_path, sep=';')\n",
    "        self._data = data_info.loc[data_info['part'] == part_name, :].reset_index(drop=True)\n",
    "        self.uniq_labels = self._data['label'].unique()\n",
    "        self.labels_map = {label: i for i, label in enumerate(self.uniq_labels)}\n",
    "        self.processor = processor\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = f\"{self._data['relative_path'][idx]}/{self._data['image_name'][idx]}\"\n",
    "        image = cv2.imread(image_path)[...,::-1]\n",
    "        image = torch.tensor(self.processor(image)['pixel_values'][0])\n",
    "        label = self.labels_map[self._data['label'][idx]]\n",
    "\n",
    "        return image, label\n",
    "    \n",
    "    def __getitems__(self, idxs):\n",
    "        return [self.__getitem__(idx) for idx in idxs]\n",
    "        \n",
    "\n",
    "def custom_collate(data):\n",
    "\n",
    "    images = torch.cat([torch.unsqueeze(item[0], 0) for item in data], 0)\n",
    "    labels = torch.tensor([item[1] for item in data])\n",
    "\n",
    "    return {\n",
    "        \"images\": images, \n",
    "        \"labels\": labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TT_INFO = './data/tt_union_fronts_info.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNextImageProcessor {\n",
       "  \"crop_pct\": 0.875,\n",
       "  \"do_normalize\": true,\n",
       "  \"do_rescale\": true,\n",
       "  \"do_resize\": true,\n",
       "  \"image_mean\": [\n",
       "    0.485,\n",
       "    0.456,\n",
       "    0.406\n",
       "  ],\n",
       "  \"image_processor_type\": \"ConvNextImageProcessor\",\n",
       "  \"image_std\": [\n",
       "    0.229,\n",
       "    0.224,\n",
       "    0.225\n",
       "  ],\n",
       "  \"resample\": 3,\n",
       "  \"rescale_factor\": 0.00392156862745098,\n",
       "  \"size\": {\n",
       "    \"shortest_edge\": 224\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_processor = AutoImageProcessor.from_pretrained(\"./base_models/microsoft_resnet50\")\n",
    "m2f_processor = AutoImageProcessor.from_pretrained(\"./base_models/facebook-m2f_swin_large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets\n",
    "train_dataset = CustomCarDataset('train', TT_INFO, m2f_processor)\n",
    "eval_dataset = CustomCarDataset('eval', TT_INFO, m2f_processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, \n",
    "                              shuffle=True, \n",
    "                              collate_fn=custom_collate)\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=16,\n",
    "                              collate_fn=custom_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 384, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/700 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 384, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/175 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# TEST\n",
    "\n",
    "print(next(iter(train_dataloader))['images'].shape)\n",
    "for batch in tqdm(train_dataloader):\n",
    "    break\n",
    "\n",
    "print(next(iter(eval_dataloader))['images'].shape)\n",
    "for batch in tqdm(eval_dataloader):\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
