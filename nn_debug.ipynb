{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Назначение:</b> <br>\n",
    "Отладка используемых архитектур нейронных сетей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoImageProcessor, ResNetForImageClassification, Mask2FormerForUniversalSegmentation\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESNET_MODEL_NAME = \"./base_models/microsoft_resnet50\"\n",
    "CLASSES = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50Classifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ResNet50Classifier, self).__init__()\n",
    "        \n",
    "        #\n",
    "        model = ResNetForImageClassification.from_pretrained(RESNET_MODEL_NAME)\n",
    "        model.requires_grad_(False)\n",
    "\n",
    "        # ResNet backbone\n",
    "        self.backbone = model.resnet\n",
    "\n",
    "        #\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(start_dim=1, end_dim=-1),\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoder_output = self.backbone(x)\n",
    "        out = self.fc(encoder_output)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50Classifier(CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1056270"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([ p.numel() for p in model.parameters() if p.requires_grad])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MaskFormerNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "M2F_MODEL_NAME = \"./base_models/facebook-m2f_swin_large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mask2FormerClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Mask2FormerClassifier, self).__init__()\n",
    "        \n",
    "        #\n",
    "        m2f = Mask2FormerForUniversalSegmentation.from_pretrained(M2F_MODEL_NAME)\n",
    "        m2f.requires_grad_(False)\n",
    "        self.bb_features = 1536\n",
    "\n",
    "        # M2F backbone\n",
    "        self.embeddings = m2f.model.pixel_level_module.encoder.embeddings\n",
    "        self.encoder = m2f.model.pixel_level_module.encoder.encoder\n",
    "        self.layernorm = nn.LayerNorm(self.bb_features)\n",
    "        self.pooler = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "        #\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.bb_features, 512),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(self.bb_features, 256),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(256, num_classes)\n",
    "    )\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedding_output, input_dimensions = self.embeddings(x)\n",
    "        encoder_outputs = self.encoder(embedding_output, input_dimensions)\n",
    "        \n",
    "        sequence_output = encoder_outputs.last_hidden_state\n",
    "        sequence_output = self.layernorm(sequence_output)\n",
    "\n",
    "        pooled_output = self.pooler(sequence_output.transpose(1, 2))\n",
    "        pooled_output = torch.flatten(pooled_output, 1)\n",
    "\n",
    "        out = self.fc(pooled_output)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Mask2FormerClassifier(CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1187086"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([ p.numel() for p in model.parameters() if p.requires_grad])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConvNet (my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORM_MYCNN = A.Compose([\n",
    "    A.Resize(height=224, width=224)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCNNClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(MyCNNClassifier, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            # Bx3x224x224\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.Conv2d(3, 32, kernel_size=4, stride=2),\n",
    "            # Bx32x111x111\n",
    "            nn.SiLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.AvgPool2d(kernel_size=3, stride=2, padding=1),\n",
    "            # Bx32x56x56\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            # Bx64x27x27\n",
    "            nn.SiLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.AvgPool2d(kernel_size=3, stride=2),\n",
    "            # Bx64x13x13\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=3),\n",
    "            # Bx128x4x4\n",
    "            nn.SiLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            # Bx128x2x2\n",
    "        )\n",
    "\n",
    "        self.linear_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=512, out_features=64),\n",
    "            # Bx64\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(in_features=64, out_features=num_classes)\n",
    "            # Bxnum_classes\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        conv_out = self.conv_layers(x)\n",
    "        out = self.linear_layers(conv_out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyCNNClassifier(CLASSES, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205428"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([ p.numel() for p in model.parameters() if p.requires_grad])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
